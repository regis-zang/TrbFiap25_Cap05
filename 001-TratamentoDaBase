# ðŸ“Š Resumo dos Ajustes de Qualidade de Dados em Python

Este documento resume as transformaÃ§Ãµes e limpezas aplicadas aos datasets ao longo do projeto, visando garantir **acurÃ¡cia**, **consistÃªncia** e **prontidÃ£o para visualizaÃ§Ã£o**.

## 1. **Tratamento de EspaÃ§os e Caracteres**

- **RemoÃ§Ã£o de espaÃ§os extras** em nomes de campos e valores.
    
    - Exemplo: `"Santa Catarina"` â†’ `"Santa Catarina"`.
        
- **PadronizaÃ§Ã£o de acentos** e remoÃ§Ã£o de caracteres especiais via `unidecode` para facilitar buscas e cruzamentos.
    
- **Trim** (remoÃ§Ã£o de espaÃ§os em branco no inÃ­cio e fim de strings) aplicado em todas as colunas de texto.
    

## 2. **PadronizaÃ§Ã£o de Colunas**

- UniformizaÃ§Ã£o dos nomes das colunas para **snake_case** (ex.: `RegiÃ£o PaÃ­s` â†’ `regiao_pais`).
    
- InclusÃ£o de campos obrigatÃ³rios no parquet final:
    
    - `centro_distribuicao`
        
    - `responsavel_pedido`
        
    - `cod_pedido`
        

## 3. **CorreÃ§Ã£o e InferÃªncia de Valores Ausentes**

- CÃ¡lculo automÃ¡tico da coluna **quantidade** quando ausente:
    
    python
    
    CopiarEditar
    
    `quantidade = valor_total_bruto / valor_unitario`
    
- SubstituiÃ§Ã£o de valores nulos ou invÃ¡lidos (`#N/A`, `(nullo)`, `(nÃ£o atribuÃ­do)`) por `#` quando definido em regra de negÃ³cio.
    
- Garantia de que colunas como **fornecedor_id**, **detalhe_id**, **centro_custo_id** e **essencialidade_id** possuam valores padrÃ£o `#` conforme solicitado.
    

## 4. **Enriquecimento de Dados**

- InclusÃ£o de **regiÃ£o_pais** e **estado** limpos e padronizados, garantindo compatibilidade com outras dimensÃµes.
    
- Garantia de consistÃªncia entre **versÃ£o de categoria** e **campo categoria** para integraÃ§Ã£o com SAC.
    

## 5. **Formatos e ExportaÃ§Ãµes**

- GeraÃ§Ã£o de arquivos **Parquet** e **CSV** contendo todos os campos originais mais os campos enriquecidos.
    
- Uso de `pyarrow` com compressÃ£o `snappy` para otimizar tamanho e performance na leitura.
    

## 6. **ValidaÃ§Ã£o Final**

- Checagem de colunas obrigatÃ³rias antes do salvamento.
    
- ComparaÃ§Ã£o amostral entre a base original e a tratada para garantir que **nenhuma informaÃ§Ã£o relevante foi perdida** no processo.
    
- Logs informativos durante a execuÃ§Ã£o para rastrear cada transformaÃ§Ã£o.
    

---

âœ… **Resultado esperado**: dataset final **limpo**, **padronizado** e **pronto** para ser usado em dashboards e anÃ¡lises visuais, garantindo consistÃªncia entre dimensÃµes e fatos.

# Etapas
```mermaid
flowchart TD
    A[IngestÃ£o de Dados - CSV] --> B[Limpeza de Texto - trim e remoÃ§Ã£o de espaÃ§os duplos]
    B --> C[PadronizaÃ§Ã£o - nomes snake_case e colunas obrigatÃ³rias]
    C --> D[CorreÃ§Ãµes e InferÃªncias - nulos e cÃ¡lculo de quantidade]
    D --> E[Enriquecimento - estado e regiao_pais consistentes]
    E --> F[ValidaÃ§Ã£o - regras, checagens e amostragens]
    F --> G[ExportaÃ§Ã£o - Parquet e CSV]
    G --> H[(Dataset Pronto para VisualizaÃ§Ã£o)]

```

flowchart LR
B(Date Dim) === C{Fact Table}
D(Symbol Dim) === C{Fact Table}
E(Company Dim) === C{Fact Table}
C{Fact Table} -.Stock Values.-> A[Measures]
A[Measures] === Z[Calculations]




